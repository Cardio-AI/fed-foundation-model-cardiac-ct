{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from monai.inferers import sliding_window_inference\n",
    "from src.utils import pts_from_mps, mps_from_pts\n",
    "from src.models.multihead_swinunetr import MultiHeadSwinUNETR\n",
    "from src.models.nnunet import nnunet_configuration, MultiHeadnnUNet\n",
    "from tavi_predictor import TAVIPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = Path('/mnt/hdd/data/FLOTO_ImageCas_Subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = {\n",
    "    'Federated': {\n",
    "        'UNet': './checkpoints/federated_hps_conditioned_on_heart.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/hinge_points/swin_unetr_heidelberg_muenster_goettingen_conditioned_on_heart_seg.pt'\n",
    "    },\n",
    "    'KD': {\n",
    "        'UNet': 'checkpoints/kd/nnunet_conditioned_on_heart_seg_heidelberg.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/kd/swin_unetr_conditioned_on_heart_seg_heidelberg_munich_goettingen_hps_finetuned.pt'\n",
    "    },\n",
    "    'Heidelberg': {\n",
    "        'UNet': 'checkpoints/hinge_points/nnunet_heidelberg_conditioned_on_heart_seg.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/hinge_points/swin_unetr_heidelberg_conditioned_on_heart_seg.pt'\n",
    "    },\n",
    "    'Muenster': {\n",
    "        'UNet': 'checkpoints/hinge_points/nnunet_muenster_conditioned_on_heart_seg2.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/hinge_points/swin_unetr_muenster_conditioned_on_heart_seg2.pt'\n",
    "    },\n",
    "    'Munich': {\n",
    "        'UNet': 'checkpoints/hinge_points/nnunet_munich_conditioned_on_heart_seg2.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/hinge_points/swin_unetr_munich_conditioned_on_heart_seg2.pt'\n",
    "    },\n",
    "    'Goettingen': {\n",
    "        'UNet': 'checkpoints/hinge_points/nnunet_goettingen_conditioned_on_heart_seg2.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/hinge_points/swin_unetr_goettingen_conditioned_on_heart_seg2.pt'\n",
    "    },\n",
    "    'Hamburg': {\n",
    "        'UNet': 'checkpoints/hinge_points/nnunet_hamburg_conditioned_on_heart_seg.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/hinge_points/swin_unetr_hamburg_conditioned_on_heart_seg2.pt'\n",
    "    },\n",
    "    'Frankfurt': {\n",
    "        'UNet': 'checkpoints/hinge_points/nnunet_frankfurt_conditioned_on_heart_seg.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/hinge_points/swin_unetr_frankfurt_conditioned_on_heart_seg2.pt'\n",
    "    },\n",
    "    'Greifswald': {\n",
    "        'UNet': 'checkpoints/hinge_points/nnunet_greifswald_conditioned_on_heart_seg.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/hinge_points/swin_unetr_greifswald_conditioned_on_heart_seg2.pt'\n",
    "    },\n",
    "    'Berlin': {\n",
    "        'UNet': 'checkpoints/hinge_points/nnunet_berlin_conditioned_on_heart_seg.pt',\n",
    "        'SWIN-UNETR': 'checkpoints/hinge_points/swin_unetr_berlin_conditioned_on_heart_seg2.pt'\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(\n",
    "        model,\n",
    "        dst,\n",
    "        condition_on_heart_seg=True,\n",
    "        sliding_window=False,\n",
    "        device='cuda'\n",
    "):\n",
    "    dst.mkdir(exist_ok=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    tp = TAVIPredictor(fname='.', tmp_dir='./tmp',)\n",
    "    for img_path in tqdm((src / 'images').iterdir()):\n",
    "        subject = img_path.name.replace('.nii.gz', '')\n",
    "        heart_roi_fname = src / 'Totalsegmentator' / f'{subject}_heart_roi.nii.gz'\n",
    "        heart_seg_fname = src / 'Totalsegmentator' / f'{subject}_heart_seg.nii.gz'\n",
    "        heart_roi = sitk.ReadImage(heart_roi_fname)\n",
    "        heart_seg = sitk.ReadImage(heart_seg_fname)\n",
    "\n",
    "        x_torch, heart_roi_res, heart_seg_res = tp.transform(heart_roi, heart_seg)\n",
    "\n",
    "        if not condition_on_heart_seg:\n",
    "            x_torch = x_torch[:,:1]\n",
    "        \n",
    "        if sliding_window:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = sliding_window_inference(x_torch, (96,96,96), 4, model)\n",
    "        else:\n",
    "            logits = model(x_torch.to(device))\n",
    "            \n",
    "        if type(logits) == tuple:\n",
    "            logits = logits[0]\n",
    "        if type(logits) == dict:\n",
    "            logits = logits['hps']\n",
    "        if type(logits) == list:\n",
    "            logits = logits[0]\n",
    "        \n",
    "        pred = torch.argmax(logits, dim=1)[0].cpu()\n",
    "        pts_idx_pred, hps = tp.pts_from_pred(pred, heart_roi_res)\n",
    "        # print(hps.shape)\n",
    "        if len(hps)==0:\n",
    "            continue\n",
    "        \n",
    "        mps_from_pts(hps, dst / f'{subject}.mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc, ckpt_paths in EXPERIMENTS.items():\n",
    "    for model_name, ckpt_path in ckpt_paths.items():\n",
    "        if not len(ckpt_path):\n",
    "            continue\n",
    "        dst = src / f'{loc}_{model_name}'\n",
    "        if dst.exists():\n",
    "            continue\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "        if 'model' in ckpt:\n",
    "            ckpt = ckpt['model']\n",
    "        if model_name == 'UNet':\n",
    "            if 'seg_layers.hps.0.weight' in ckpt:\n",
    "                model = MultiHeadnnUNet(num_input_channels=2, num_segmentation_heads={'hps': 6})\n",
    "            else:\n",
    "                model = nnunet_configuration(num_segmentation_heads=6, num_input_channels=2)\n",
    "            ckpt = {k.replace('unet.', ''): v for k, v in ckpt.items() if k != 'fed_task'}\n",
    "        elif model_name == 'SWIN-UNETR':\n",
    "            model = MultiHeadSwinUNETR(\n",
    "                out_channels={'hps': 6},\n",
    "                img_size=(96,96,96), \n",
    "                in_channels=2, \n",
    "                intermediate_out_channels=1,\n",
    "                ckpt_path=None\n",
    "            ).cuda()\n",
    "\n",
    "        ckpt = {\n",
    "            k: v for k, v in ckpt.items() \n",
    "            if not any([k.startswith(s) for s in ['outs.ms', 'outs.calc', 'outs.heart', 'seg_layers.ms', 'seg_layers.heart', 'seg_layers.calc']])\n",
    "        }\n",
    "        for k in ['fed_task', 'patches', 'deep_supervision', 'condition_on_seg', 'output_seg']:\n",
    "            if k in ckpt:\n",
    "                del ckpt[k]\n",
    "        print(loc)\n",
    "        model.load_state_dict(ckpt)\n",
    "        \n",
    "        eval_model(\n",
    "            model=model,\n",
    "            dst=dst,\n",
    "            condition_on_heart_seg=True,\n",
    "            sliding_window=model_name == 'SWIN-UNETR',\n",
    "            device='cuda'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = ['Frankfurt', 'Hamburg', 'Muenster', 'Greifswald', 'Berlin', 'Heidelberg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_labels = ['RCC', 'LCC', 'NCC', 'RCA', 'LCA']\n",
    "data, data2 = [], {}\n",
    "# for pts_path in src.glob('*/*.mps'):\n",
    "for loc in locs:\n",
    "    for pts_path in (src /'Human' / loc).glob('*.mps'):\n",
    "    # loc = pts_path.parent.name\n",
    "        if loc not in locs:\n",
    "            continue\n",
    "        if loc not in data2:\n",
    "            data2[loc] = {}\n",
    "        subject = pts_path.stem\n",
    "        pts = pts_from_mps(pts_path)\n",
    "        if loc == 'Greifswald':\n",
    "            pts = pts[[1,0,2,4,3]]\n",
    "        if pts.shape[0] < 5:\n",
    "            continue\n",
    "        data2[loc][subject] = pts\n",
    "        pts_data = {f'{l}_{c}': pt_c for l, pt in zip(pts_labels, pts) for c, pt_c in zip('xyz', pt)}\n",
    "        pts_data['location'] = loc\n",
    "        pts_data['subject'] = pts_path.stem\n",
    "        pts_data['model'] = 'human'\n",
    "        data.append(pts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['UNet', 'SWIN-UNETR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    for pts_path in src.glob(f'*_{model_name}/*.mps'):\n",
    "        # loc = pts_path.parent.name.split('_')[0]\n",
    "        model = pts_path.parent.name\n",
    "        if model not in data2:\n",
    "            data2[model] = {}\n",
    "        subject = pts_path.stem\n",
    "        pts = pts_from_mps(pts_path)\n",
    "        # if loc == 'Greifswald':\n",
    "        #     pts = pts[[1,0,2,4,3]]\n",
    "        # if pts.shape[0] < 5:\n",
    "        #     continue\n",
    "\n",
    "        pts_gt = data2['Heidelberg'][subject]\n",
    "        pts_proc = {l: np.array([np.nan,np.nan,np.nan])[None] for l in pts_labels}\n",
    "        for pt in pts:\n",
    "            pt_distances = [np.linalg.norm(pt - pt_gt) for pt_gt in pts_gt]\n",
    "            pt_label = pts_labels[np.argmin(pt_distances)]\n",
    "            pts_proc[pt_label] = pt[None]\n",
    "\n",
    "        pts = np.concatenate(list(pts_proc.values()), axis=0)        \n",
    "        data2[model][subject] = pts\n",
    "        pts_data = {f'{l}_{c}': pt_c for l, pt in zip(pts_labels, pts) for c, pt_c in zip('xyz', pt)}\n",
    "        pts_data['location'] = model.split('_')[0]\n",
    "        pts_data['subject'] = pts_path.stem\n",
    "        pts_data['model'] = model_name\n",
    "        data.append(pts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = df[df.location == 'Berlin'].subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_mean, pts_std = {}, {}\n",
    "for subject in subjects:\n",
    "    subject_pts = [pts[subject][:5][None] for loc, pts in data2.items() if loc in locs] # not in ['Model2']]\n",
    "    subject_pts = np.concatenate(subject_pts, axis=0)\n",
    "    pts_mean[subject] = subject_pts.mean(axis=0)\n",
    "    pts_std[subject] = subject_pts.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = {}\n",
    "for subject in subjects:\n",
    "    subject_pts_mean = pts_mean[subject]\n",
    "    for loc in df.location.unique():\n",
    "        k = f'{loc}_human'\n",
    "        if loc in data2:\n",
    "            if k not in distances:\n",
    "                distances[k] = []\n",
    "            subject_pts_loc = data2[loc][subject]\n",
    "            loc_distance = np.linalg.norm(subject_pts_mean - subject_pts_loc[:5], axis=1)\n",
    "            distances[k].append(loc_distance[None])\n",
    "        for m in df.model.unique():\n",
    "            if m == 'human': \n",
    "                continue\n",
    "            k = f'{loc}_{m}'\n",
    "            if k not in data2 or subject not in data2[k]:\n",
    "                continue\n",
    "            if k not in distances:\n",
    "                distances[k] = []\n",
    "            subject_pts_m = data2[k][subject]\n",
    "            m_distance = np.linalg.norm(subject_pts_mean - subject_pts_m[:5], axis=1)\n",
    "            distances[k].append(m_distance[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distances = []\n",
    "for loc, loc_distances in distances.items():\n",
    "    for d, subject in zip(loc_distances, subjects):\n",
    "        d_data = {'location': loc, 'subject': subject}\n",
    "        for l, dd in zip(pts_labels, d[0]):\n",
    "            d_data[l] = dd\n",
    "        df_distances.append(d_data)\n",
    "df_distances = pd.DataFrame(df_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(x):\n",
    "    if 'human' in x:\n",
    "        return 'H'\n",
    "    elif 'Federated' in x:\n",
    "        if 'UNet' in x:\n",
    "            return 'FU'\n",
    "        else:\n",
    "            return 'FT'\n",
    "    elif 'KD' in x:\n",
    "        if 'UNet' in x:\n",
    "            return 'KDU'\n",
    "        else:\n",
    "            return 'KDT'\n",
    "    else:\n",
    "        # return 2\n",
    "        if 'UNet' in x:\n",
    "            return 'LU'\n",
    "        else:\n",
    "            return 'LT'\n",
    "    \n",
    "df_distances['location2'] = df_distances.location.apply(filter_fn) # .isin(locs)\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15,3))\n",
    "for i, (l, ax) in enumerate(zip(pts_labels, axs)):\n",
    "    sns.boxplot(data=df_distances[df_distances.location2!='KDU'], x='location2', y=l, ax = ax) # hue='location')\n",
    "    \n",
    "    ax.set_title(l)\n",
    "    # ax.set_ylim([-0.2,10.2])\n",
    "    ax.set_yscale('log')\n",
    "    xlabels = ax.get_xticklabels()\n",
    "    # [xl.set_text(t) for xl, t in zip(xlabels, ['H', 'LU', 'LT', 'FU', 'FT', 'KDU', 'KDT'])]\n",
    "    ax.set_xticklabels(xlabels)\n",
    "    ax.set_xlabel(None)\n",
    "    if i:\n",
    "        ax.set_ylabel(None)\n",
    "        ax.set_yticklabels([])\n",
    "    else:\n",
    "        ax.set_ylabel('d [mm]')\n",
    "fig.tight_layout()\n",
    "fig.savefig('./images/public_comparison_interobserver_variability.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = df_distances[df_distances.location2!='KDU'].groupby('location2')[pts_labels].mean()\n",
    "means.mean(axis=1), means.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = []\n",
    "for i, row in df_distances[df_distances.location2!='KDU'].iterrows():\n",
    "    for j, l in enumerate(pts_labels):\n",
    "        k = 'distance_hps' if j < 3 else 'distance_ca'\n",
    "        flattened_data.append({\n",
    "            # 'train_location': row.train_location, \n",
    "            # 'test_location': row.test_location, \n",
    "            'location': row.location2,\n",
    "            # 'model': row.model,\n",
    "            # 'method': row.method,\n",
    "            k: row[l]\n",
    "        })\n",
    "flattened_df = pd.DataFrame(flattened_data)\n",
    "fig,axs = plt.subplots(1, 2, figsize=(12,5))\n",
    "order = ['H', 'LU', 'LT', 'FU', 'FT', 'KDT']\n",
    "sns.boxplot(data=flattened_df, x='location', y='distance_hps', ax=axs[0], order=order)\n",
    "sns.boxplot(data=flattened_df, x='location', y='distance_ca', ax=axs[1], order=order)\n",
    "for ax in axs:\n",
    "    ax.set_yscale('log')\n",
    "    # ax.set_ylim([0,10])\n",
    "    ax.set_xlabel('Method')\n",
    "    ax.set_ylabel('d [mm]')\n",
    "axs[0].set_title('Hinge Points')\n",
    "axs[1].set_title('Coronary Arteries')\n",
    "axs[-1].set_ylabel(None)\n",
    "axs[-1].set_yticklabels([])\n",
    "fig.tight_layout()\n",
    "fig.savefig('images/performance_methods_public_dataset.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = []\n",
    "for i, row in df_distances[df_distances.location2!='KDU'].iterrows():\n",
    "    for j, l in enumerate(pts_labels):\n",
    "        k = 'distance' # _hps' if j < 3 else 'distance_ca'\n",
    "        flattened_data.append({\n",
    "            # 'train_location': row.train_location, \n",
    "            # 'test_location': row.test_location, \n",
    "            'location': row.location2,\n",
    "            # 'model': row.model,\n",
    "            # 'method': row.method,\n",
    "            k: row[l]\n",
    "        })\n",
    "flattened_df = pd.DataFrame(flattened_data)\n",
    "fig,ax = plt.subplots(1, 1, figsize=(7,4))\n",
    "order = ['H', 'LU', 'LT', 'FU', 'FT', 'KDT']\n",
    "sns.boxplot(data=flattened_df, x='location', y='distance', ax=ax, order=order)\n",
    "# sns.boxplot(data=flattened_df, x='location', y='distance_ca', ax=axs[1], order=order)\n",
    "# for ax in axs:\n",
    "ax.set_yscale('log')\n",
    "# ax.set_ylim([0,10])\n",
    "ax.set_xlabel('Method')\n",
    "ax.set_ylabel('d [mm]')\n",
    "ax.set_title(r'Hinge Points and Coronary Ostia (HPs and COs) $\\downarrow$', fontsize=16)\n",
    "ax.set_xticklabels(['Human', 'UNet', 'SWIN-UNETR', 'FedUNet', 'FedSWIN-\\nUNETR', 'FedKDSWIN-\\nUNETR'])\n",
    "ax.set_xlabel(None)\n",
    "# axs[1].set_title('Coronary Arteries')\n",
    "# axs[-1].set_ylabel(None)\n",
    "# axs[-1].set_yticklabels([])\n",
    "fig.tight_layout()\n",
    "fig.savefig('notebooks/images2/performance_methods_public_dataset.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = flattened_df.groupby('location')['distance'].median()\n",
    "q25 = flattened_df.groupby('location')['distance'].quantile(.25)\n",
    "q75 = flattened_df.groupby('location')['distance'].quantile(.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['H', 'LU', 'LT', 'FU', 'FT', 'KDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    m = np.round(medians[method],2)\n",
    "    mq25 = np.round(q25[method],2)\n",
    "    mq75 = np.round(q75[method],2)\n",
    "    iqr = mq75 - mq25\n",
    "    print(f\"{method}  ${m}\\,(\\mathrm{{IQR:}}{iqr:.2f})\\,\\mathrm{{mm}}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
